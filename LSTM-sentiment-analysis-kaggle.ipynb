{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Desafio Kaggle - Sentiment Analysis\n",
    "\n",
    "O presente desafio foi retirado do site https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews\n",
    "\n",
    "Os dados foram baixados através do site, na aba \"Data\". Os dados constituem dois conjuntos de críticas do filme \"The Rotten Tomatoes\": um para treinamento e outro para teste de benchmarking (não possui os sentimentos rotulados). Para mais detalhes, ver o site citado acima.\n",
    "\n",
    "Já a construção da rede foi baseada em uma aula que tive da Udacity, do \"PyThorch Scholarship Challenge\", no qual aprendi sobre redes neurais profundas (CNNs, LSTMs, etc.) Não há um link específico para o código desenvolvido por eles, mas vou deixar o notebook, que utilizei como base, junto dos arquivos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados\n",
    "\n",
    "O dataset é composto de arquivos separados por \"tab\", contendo frases do dataset do Rotten Tomatoes.\n",
    "\n",
    "O arquivo 'train.tsv' contém as frases e suas correspondentes labels de sentimento. Ele também possui uma coluna chamada \"SenteceId\" que indica a qual frase aquela sentença pertence. E cada linha do documento possui uma \"PhraseId\".\n",
    "\n",
    "O objetivo é treinar um algoritmo capaz de classificar esses reviews (contidos no conjunto de treinamento) em labels de 0 a 4, sendo:\n",
    "\n",
    "0 - negativo\n",
    "\n",
    "1 - um pouco negativo\n",
    "\n",
    "2 - neutro\n",
    "\n",
    "3 - um pouco positivo\n",
    "\n",
    "4 - positivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo os arquivos:\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.tsv', sep='\\t')\n",
    "test = pd.read_csv('test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arquivo 'train.tsv'\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8544"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['SentenceId'][156059]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8544\n",
      "156060\n"
     ]
    }
   ],
   "source": [
    "# Ultima SentenceId = 8544\n",
    "\n",
    "sentence_id = [i for i in range(8545)]\n",
    "print(sentence_id[-1])\n",
    "\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arquivo 'test.tsv'\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66292, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Para possível uso futuro, escolhi criar listas separadas de cada objeto dos arquivos de treinamento:\n",
    "\n",
    "phrases = []\n",
    "sentiments = []\n",
    "appended_ids = []\n",
    "for i in range(len(train)):\n",
    "    if train['SentenceId'][i] not in appended_ids:\n",
    "        phrases.append(train['Phrase'][i])\n",
    "        sentiments.append(train['Sentiment'][i])\n",
    "        appended_ids.append(train['SentenceId'][i])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def pretty_print_review_and_label(labels, reviews, number):\n",
    "    for i in range(number):\n",
    "        print(\"Sentimento = \" + str(labels[i]) + \":\\t\" + reviews[i][:150] + \"...\\n\")\n",
    "    \n",
    "pretty_print_review_and_label(sentiments, phrases, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação de uma RNN utilizando PyTorch\n",
    "\n",
    "Escolhi utilizar a biblioteca do PyTorch, baseada na biblioteca torch, para a implementação de uma rede neural. Esta biblioteca é utilizada para aplicações de deep learning e NLP.\n",
    ">O PyTorch é um software open source gratuito e foi inicialmente desenvolvido pela equipe de pesquisa de AI do Facebook.\n",
    "\n",
    "### Arquitetura da Rede\n",
    "\n",
    "Vou, então, implementar uma rede neural recorrente que classifica os sentimentos desses reviews. Na imagem abaixo podemos ter uma melhor ideia de como ela é composta (**Obs.**: No lugar das camadas Sigmoid, vamos utilizar uma camada totalmente conectada com ativação softmax):\n",
    "\n",
    "<img src=\"network_diagram.png\" width=40%>\n",
    "\n",
    "**Primeiro, vamos passar as palavras por uma camada de \"mergulho\" (embedding layer, em inglês)**\n",
    ">Precisamos dessa camada inicial pois temos milhares de palavras e precisamos ser mais eficientes nas representações de nossos dados de input. No nosso caso, esta camada é utilizada para fins de redução da dimensionalidade. Utilizando essa camada de mergulho, e deixando o algoritmo aprender sozinho uma nova representação, já é possível obter uma boa acurácia.\n",
    "\n",
    "**Após passarmos o input na camada de mergulho, os novos embeddings são passados pelas células LSTMs**\n",
    ">A LSTM é responsável por adicionar conexões recorrentes eficientes para o tratamento de textos, nos dando informações sobre a sequência de texto, ao invés de informações das palavras de forma isolada.\n",
    "\n",
    "**Por fim, a LSTM gera um output que é passado por uma última camada totalmente conectada**\n",
    ">A última camada vai ser composta por uma camada totalmente conectada (de 5 neurons), pois temos 5 tipos de inputs diferentes. Por fim, a função de ativação escolhida vai ser a função softmax, que é uma boa escolha para tratar a classificação multiclasse.\n",
    "\n",
    "(Considerando a imagem anterior, não é necessário se preocupar com as saídas da função de ativação, exceto para a **última**; podendo ignorar as restantes. Mais a frente, vamos calcular a loss function comparando o output do último passo com os labels de treinamento.)\n",
    "\n",
    "----\n",
    "## Pré-processamento dos dados\n",
    "\n",
    "O primeiro passo antes de construir a rede neural é transformar os dados na melhor forma para inserir na rede. Como vamos usar camadas de embedding, vai ser necessário codificar cada palavra como um inteiro. Além disso, também é necessário \"limpar\" os ruídos.\n",
    "\n",
    "Os passos de processamento serão divididos em:\n",
    ">* Vamos reduzir o noise dos dados, obtendo uma nova tabela de treinamento com menos frases (Vamos inicialmente considerar apenas as frases inteiras);\n",
    "* Vamos excluir os períodos e pontuações diversas (se houverem);\n",
    "* Por fim, vamos combinar todas as palavras em uma grande string para codificar as palavras em vetores unitários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos então reabrir os arquivos e entender como eles se organizam:\n",
    "\n",
    "g = open('train.tsv','r')\n",
    "train = list(map(lambda x: x[:-1], g.readlines()))\n",
    "g.close()\n",
    "\n",
    "g = open('test.tsv','r')\n",
    "test = list(map(lambda x: x[:-1], g.readlines()))\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PhraseId\\tSentenceId\\tPhrase\\tSentiment',\n",
       " '1\\t1\\tA series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .\\t1',\n",
       " '2\\t1\\tA series of escapades demonstrating the adage that what is good for the goose\\t2',\n",
       " '3\\t1\\tA series\\t2',\n",
       " '4\\t1\\tA\\t2',\n",
       " '5\\t1\\tseries\\t2',\n",
       " '6\\t1\\tof escapades demonstrating the adage that what is good for the goose\\t2',\n",
       " '7\\t1\\tof\\t2',\n",
       " '8\\t1\\tescapades demonstrating the adage that what is good for the goose\\t2',\n",
       " '9\\t1\\tescapades\\t2']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PhraseId\\tSentenceId\\tPhrase',\n",
       " '156061\\t8545\\tAn intermittently pleasing but mostly routine effort .',\n",
       " '156062\\t8545\\tAn intermittently pleasing but mostly routine effort',\n",
       " '156063\\t8545\\tAn',\n",
       " '156064\\t8545\\tintermittently pleasing but mostly routine effort',\n",
       " '156065\\t8545\\tintermittently pleasing but mostly routine',\n",
       " '156066\\t8545\\tintermittently pleasing but',\n",
       " '156067\\t8545\\tintermittently pleasing',\n",
       " '156068\\t8545\\tintermittently',\n",
       " '156069\\t8545\\tpleasing']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceId: 1\n",
      "Frase: A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .\n",
      "Sentimento: 1\n"
     ]
    }
   ],
   "source": [
    "# Vamos por partes... Primeiramente vejamos uma forma de separar cada frase do treinamento\n",
    "\n",
    "linha_1 = train[1]\n",
    "lista_teste = linha_1.split('\\t')\n",
    "print(\"SentenceId: \" + lista_teste[1] +\"\\nFrase: \" + lista_teste[2] + \"\\nSentimento: \" + lista_teste[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['PhraseId', 'SentenceId', 'Phrase', 'Sentiment'], ['1', '1', 'A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .', '1'], ['2', '1', 'A series of escapades demonstrating the adage that what is good for the goose', '2'], ['3', '1', 'A series', '2'], ['4', '1', 'A', '2']]\n"
     ]
    }
   ],
   "source": [
    "# Fazendo isso para todos os dados (primeiro para treinamento):\n",
    "\n",
    "train_lines = []\n",
    "for i in range(len(train)):\n",
    "    train_lines.append(train[i])\n",
    "\n",
    "train_set_lines = []\n",
    "for i in range(len(train_lines)):\n",
    "    dados_linha = train_lines[i]\n",
    "    dados_linha = dados_linha.split('\\t')\n",
    "    train_set_lines.append(dados_linha)\n",
    "\n",
    "print(train_set_lines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['PhraseId', 'SentenceId', 'Phrase'], ['156061', '8545', 'An intermittently pleasing but mostly routine effort .'], ['156062', '8545', 'An intermittently pleasing but mostly routine effort'], ['156063', '8545', 'An'], ['156064', '8545', 'intermittently pleasing but mostly routine effort']]\n"
     ]
    }
   ],
   "source": [
    "# E agora para os dados de teste:\n",
    "\n",
    "test_lines = []\n",
    "for i in range(len(test)):\n",
    "    test_lines.append(test[i])\n",
    "\n",
    "test_set_lines = []\n",
    "for i in range(len(test_lines)):\n",
    "    dados_linha = test_lines[i]\n",
    "    dados_linha = dados_linha.split('\\t')\n",
    "    test_set_lines.append(dados_linha)\n",
    "\n",
    "print(test_set_lines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['50', '1', 'none of which amounts to much of a story', 1]\n"
     ]
    }
   ],
   "source": [
    "# Arrumando o tipo do dado \"Sentiment\". Vamos transformar as strings\n",
    "# em inteiros:\n",
    "\n",
    "for i in range(1, len(train_set_lines)):\n",
    "    train_set_lines[i][3] = int(train_set_lines[i][3])\n",
    "    \n",
    "print(train_set_lines[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrumando as frases. Vamos substituir todas as maiusculas por\n",
    "# minusculas e tirar quaisquer pontuaçoes desnecessárias dos dados\n",
    "# (tanto de treinamento quanto de teste):\n",
    "\n",
    "import re # Esta é a biblioteca ReGex, usada para auxiliar a localização\n",
    "          # de padrões\n",
    "\n",
    "for i in range(len(train_set_lines)):\n",
    "    train_set_lines[i][2] = train_set_lines[i][2].lower()\n",
    "    string = train_set_lines[i][2]\n",
    "    train_set_lines[i][2] = re.sub('[^a-z0-9\\s]', '', string)\n",
    "    \n",
    "for i in range(len(test_set_lines)):\n",
    "    test_set_lines[i][2] = test_set_lines[i][2].lower()\n",
    "    string = test_set_lines[i][2]\n",
    "    test_set_lines[i][2] = re.sub('[^a-z0-9\\s]', '', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentimento: 1\n",
      "Frase para treino: none of which amounts to much of a story\n",
      "\n",
      "Frase para teste: an intermittently pleasing but mostly routine effort \n"
     ]
    }
   ],
   "source": [
    "print(\"Sentimento: \"+str(train_set_lines[50][3])+\"\\nFrase para treino: \"+train_set_lines[50][2])\n",
    "print()\n",
    "print(\"Frase para teste: \"+test_set_lines[1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a series of escapades demonstrating the adage that what is good for the goose is also good for the gander  some of which occasionally amuses but none of which amounts to much of a story  a series of escapades demonstrating the adage that what is good for the goose a series a series of escapades demonstrating the adage that what is good for the goose of escapades demonstrating the adage that what is good for the goose escapades demonstrating the adage that what is good for the goose demonstrating the adage demonstrating the adage the adage that what is good for the goose that what is good for the goose what is good for the goose is good for the goose good for the goose for the goose goose is also good for the gander  some of which occasionally amuses but none of which amounts to much of a story  is also good for the gander  some of which occasionally amuses but none of which amounts to much of a story is also also good for the gander  some of which occasionally amuses but none of which \n"
     ]
    }
   ],
   "source": [
    "# Vamos agora criar uma lista de palavras (um vocabulário\n",
    "# para uso futuro):\n",
    "\n",
    "all_text = []\n",
    "for i in range(1,len(train_set_lines)):\n",
    "    all_text.append(train_set_lines[i][2])\n",
    "\n",
    "for i in range(1,len(test_set_lines)):\n",
    "    all_text.append(test_set_lines[i][2])\n",
    "\n",
    "all_text = ' '.join(all_text)\n",
    "print(all_text[:1000])\n",
    "\n",
    "# Para quem manja de comprehensions, podemos escrever o mesmo\n",
    "# código acima como:\n",
    "# all_text_comprehension = ' '.join([train_set_lines[i][2] for i in range(1,len(train_set_lines))])\n",
    "# print(all_text_comprehension[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'series', 'of', 'escapades', 'demonstrating', 'the', 'adage', 'that', 'what', 'is', 'good', 'for', 'the', 'goose', 'is', 'also', 'good', 'for', 'the', 'gander', 'some', 'of', 'which', 'occasionally', 'amuses', 'but', 'none', 'of', 'which', 'amounts']\n"
     ]
    }
   ],
   "source": [
    "words = all_text.split()\n",
    "print(words[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificando as palavras\n",
    "\n",
    "Para utilizarmos a camada de mergulho (\"embedding layer\"), precisamos passar números inteiros na rede. Uma forma de fazer isso é criando um dicionário que mapeia palavras para números, tornando possível a conversão de cada uma das palavras dos reviews em números.\n",
    "\n",
    "Mais tarde, vamos acrescentar zeros (o chamado \"padding\") nos vetores de input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos então contar as palavras (para futuras análises - opcional)\n",
    "from collections import Counter\n",
    "\n",
    "counts = Counter(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Dica pra vida**: É possivel também analisarmos separadamente as palavras que mais aparecem em cada um dos tipos de reviews (rotulados de 0 a 4). Isso pode nor dar uma ideia de quais palavras são mais vistas positivamente e quais estão mais correlacionadas com o sentimento negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de palavras em todos os reviews: 1462139\n",
      "Total de palavras no vocabulario: 19317\n"
     ]
    }
   ],
   "source": [
    "# E criar um vocabulário, ordenado a partir das palavras mais faladas\n",
    "# Obs.: Este vocabulário é composto de palavras únicas, pois\n",
    "# o método Counter() conta as aparições de cada palavra e\n",
    "# retorna um vocabulário com o número de aparições e as strings\n",
    "vocabulary = sorted(counts, key=counts.get, reverse=True)\n",
    "print(\"Total de palavras em todos os reviews: {}\".format(len(words)))\n",
    "print(\"Total de palavras no vocabulario: {}\".format(len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um novo dicionário, que mapeia cada palavra (a partir da que\n",
    "# mais aparece) em números, começando de 1:\n",
    "vocabulary_to_int = {}\n",
    "int_to_vocabulary = {}\n",
    "for i, word in enumerate(vocabulary, 1):\n",
    "    vocabulary_to_int[word] = i\n",
    "    int_to_vocabulary[i] = word\n",
    "\n",
    "# Forma alternativa, utilizando dict comprehension\n",
    "# vocabulary_to_int = {word: i for i, word in enumerate(vocabulary, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E agora transformando cada review em números\n",
    "# e 'abusando' das list comprehensions:\n",
    "train_set_int = []\n",
    "for review in train_set_lines:\n",
    "    if review[0] == 'PhraseId':\n",
    "        continue\n",
    "    train_set_int.append([vocabulary_to_int[word] for word in review[2].split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palavras únicas:  19317\n",
      "\n",
      "Review em formato token:\n",
      " [597, 3, 82, 2668, 5, 50, 3, 2, 40]\n"
     ]
    }
   ],
   "source": [
    "# Conferindo:\n",
    "print(\"Palavras únicas: \", len(vocabulary_to_int))\n",
    "print()\n",
    "print(\"Review em formato token:\\n\", train_set_int[49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "[16, 2707, 2797, 19, 494, 956, 372]\n"
     ]
    }
   ],
   "source": [
    "# E para uso futuro, vamos já deixar o vetor dos labels\n",
    "# de sentimentos pronto. O label da posição x ('encoded_label[x]')\n",
    "# corresponde ao review 'train_set_int[x]':\n",
    "import numpy as np\n",
    "\n",
    "encoded_labels = np.array([train_set_lines[i][3] for i in range(1,len(train_set_lines))])\n",
    "print(encoded_labels[49])\n",
    "\n",
    "# E os dados de teste codificados:\n",
    "test_set_int = []\n",
    "for review in test_set_lines:\n",
    "    if review[0] == 'PhraseId':\n",
    "        continue\n",
    "    test_set_int.append([vocabulary_to_int[word] for word in review[2].split()])\n",
    "\n",
    "print()\n",
    "print(test_set_int[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[597, 3, 82, 2668, 5, 50, 3, 2, 40]\n",
      "none of which amounts to much of a story\n"
     ]
    }
   ],
   "source": [
    "# Para conferir se as conversões estão de acordo com o esperado...\n",
    "\n",
    "review_49 = train_set_int[49] # review em formato token\n",
    "print(review_49)\n",
    "review_49_words = ' '.join([int_to_vocabulary[i] for i in review_49]) # refazendo a conversão\n",
    "print(review_49_words)\n",
    "\n",
    "# Obs.: a partir daqui, os dados estão \"shifted\" por uma casa a menos,\n",
    "# isso pq nos dados anteriores tínhamos os cabeçalhos (aquele com os títulos\n",
    "# das colunas em formato string)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo outliers\n",
    "\n",
    "Um passo de pre-processamento adicional é o de padronizar nossos inputs. Isto é, nossa rede vai esperar como input um vetor de tamanho fixo. Assim, queremos formatar nossos reviews em um tamanho específico.\n",
    "\n",
    "Para fazer isso, podemos dividir o processo em dois passos:\n",
    "\n",
    "1. Retirar os reviews outliers (i.e., aqueles muito compridos ou muito curtos);\n",
    "2. Preencher (o famoso *padding*) ou truncar o restante dos dados, de forma a termos reviews com o mesmo tamanho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de reviews: 156060\n",
      "Quantos reviews de tamanho nulo: 27\n",
      "Tamanho máximo de um review: 48\n"
     ]
    }
   ],
   "source": [
    "# Vamos procurar por reviews \"extremos\", aqueles\n",
    "# que podem \"bagunçar\" com o treinamento:\n",
    "\n",
    "tamanho_reviews = Counter([len(x) for x in train_set_int]) # Dict: {objeto: contagem}\n",
    "print(\"Número total de reviews: {}\".format(len(train_set_int)))\n",
    "print(\"Quantos reviews de tamanho nulo: {}\".format(tamanho_reviews[0]))\n",
    "print(\"Tamanho máximo de um review: {}\".format(max(tamanho_reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]\n",
      "\n",
      "[27053, 21554, 18032, 14614, 10981, 8813, 7252, 6131, 5202, 4505, 3954, 3460, 3013, 2676, 2422, 2150, 1872, 1689, 1443, 1327, 1215, 1054, 840, 757, 649, 590, 453, 387, 367, 296, 270, 223, 150, 129, 110, 88, 75, 57, 35, 35, 32, 27, 21, 20, 15, 7, 6, 6, 3]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(tamanho_reviews))\n",
    "print()\n",
    "print(sorted(tamanho_reviews.values(), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de reviews para teste: 66292\n",
      "Quantos reviews de teste de tamanho nulo: 21\n",
      "Tamanho máximo de review do teste: 52\n"
     ]
    }
   ],
   "source": [
    "tamanho_reviews_test = Counter([len(x) for x in test_set_int])\n",
    "print(\"Número total de reviews para teste: {}\".format(len(test_set_int)))\n",
    "print(\"Quantos reviews de teste de tamanho nulo: {}\".format(tamanho_reviews_test[0]))\n",
    "print(\"Tamanho máximo de review do teste: {}\".format(max(tamanho_reviews_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanho = sorted([key for key in tamanho_reviews.keys()])\n",
    "numero = [tamanho_reviews[lenght] for lenght in tamanho]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(tamanho, numero)\n",
    "plt.xlabel('Tamanho da review')\n",
    "plt.ylabel('Quantidade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que o tamanho da review é uma distribuição assimétrica com concentração à esquerda. Isto porque foram acrecentados dados repetidos na tabela de reviews. Lembrando lá do início do notebook, algumas frases foram sendo cortadas e adicionadas como uma nova linha e com um (às vezes novo) sentimento relacionado à frase cortada. Isto nos permite uma maior liberdade com os dados, a fim de escolhermos o que fazer com cada um deles.\n",
    "\n",
    "> Por curiosidade, a *moda* dessa distribuição é 2 (i.e., existem mais reviews de tamanho 2 do que de qualquer outro tamanho). O tamanho máximo é de 48 (no caso do conjunto de teste, o tamanho máximo é de 52, o que é um bom tamanho para inserir na rede). E o mínimo é 0 (Um \"problema\", esses reviews de tamanho nulo devem ser excluídos dos dados).\n",
    "\n",
    "No nosso caso, como dito anteriormente, vamos considerar apenas as frases maiores (desconsiderando as frases muito curtas, ou de comprimento nulo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    ">**Curiosidade**: Por quê desconsideramos os reviews de tamanho nulo? Como eles se distribuem?\n",
    "\n",
    ">Considerando que os reviews que não possuem texto, a primeira distribuição a se esperar é uma distribuição do tipo normal (totalmente aleatória). Esse é também um dos motivos para não se introduzir esses dados na rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "Counter({2: 26, 1: 1})\n"
     ]
    }
   ],
   "source": [
    "# A título de curiosidade, vamos pegar os reviews nulos para entender a sua distribuição:\n",
    "zero_idx_train = [i for i, review in enumerate(train_set_int) if len(review) == 0]\n",
    "\n",
    "# E guardando as labels dos reviews nulos:\n",
    "encoded_labels_null = [encoded_labels[i] for i in zero_idx_train]\n",
    "print(encoded_labels_null)\n",
    "count_label_null = Counter(encoded_labels_null)\n",
    "print(count_label_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_data = [0,1,2,3,4]\n",
    "y_data = [0,1,26,0,0]\n",
    "plt.plot(x_data, y_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Voltando para o nosso problema...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos então retirar os reviews de tamanho nulo e os\n",
    "# seus respectivos labels dos reviews:\n",
    "\n",
    "# Pegando os indices dos reviews de tamanho nulo:\n",
    "non_zero_idx_train = [i for i, review in enumerate(train_set_int) if len(review) != 0]\n",
    "non_zero_idx_test = [i for i, review in enumerate(test_set_int) if len(review) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de reviews antes da remoção dos reviews nulos: 156060\n",
      "Número de reviews após a remoção dos reviews nulos:  156033\n"
     ]
    }
   ],
   "source": [
    "# Removendo os reviews nulos e seus labels:\n",
    "train_set_int = [train_set_int[i] for i in non_zero_idx_train]\n",
    "encoded_labels = np.array([encoded_labels[i] for i in non_zero_idx_train])\n",
    "test_set_int = [test_set_int[i] for i in non_zero_idx_test]\n",
    "\n",
    "print(\"Número de reviews antes da remoção dos reviews nulos: 156060\")\n",
    "print(\"Número de reviews após a remoção dos reviews nulos: \", len(train_set_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizando o preenchimento (*padding*)\n",
    "\n",
    "Para lidarmos com ambas as reviews (curtas e longas), a gente pode truncar ou preencher todos os nossos reviews, constringindo os reviews a um comprimento específico.\n",
    "\n",
    "Para reviews menores que um determinado comprimento `seq_length`, a gente preenche o vetor com 0's. Para reviews maiores que esse mesmo comprimento, a gente trunca ele nas primeiras palavras.\n",
    "\n",
    "Vamos considerar inicialmente um tamanho para a `seq_length` de 48, que foi o tamanho máximo encontrado.\n",
    ">**Dica pra vida**: Caso estivéssemos lidando com reviews maiores, aqueles com até 2500 caracteres, um bom tamanho de truncagem poderia ser 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_features(review_ints, seq_length):\n",
    "    ''' Retorna vetores (features) dos review_ints contidos\n",
    "        ou preenchidos até o limite de tamanho seq_length\n",
    "    '''\n",
    "    \n",
    "    # Aqui produzimos um vetor com a forma desejada de linhas x colunas:\n",
    "    features = np.zeros((len(review_ints),seq_length), dtype=int)\n",
    "    \n",
    "    # Para cada review:\n",
    "    for i, row in enumerate(review_ints):\n",
    "        features[i, -len(row):] = np.array(row[:seq_length])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     2   296     3 17898  7572     1  8288\n",
      "      9    51     8    47    13     1  4654     8   175    47    13     1\n",
      "  13710    58     3    82   545 12678    19   597     3    82  2668     5\n",
      "     50     3     2    40]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     2   296     3 17898  7572     1  8288     9    51     8\n",
      "     47    13     1  4654]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     2   296]]\n",
      "\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0   16 2707 2797   19  494  956  372]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0   16 2707 2797   19  494  956  372]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0   16]]\n"
     ]
    }
   ],
   "source": [
    "seq_length = 52\n",
    "features_train = padding_features(train_set_int, seq_length=seq_length)\n",
    "features_test = padding_features(test_set_int, seq_length=seq_length)\n",
    "\n",
    "# Para testar o código, podemos usar assert:\n",
    "# assert len(features) == len(train_set_int), \"As features devem ter o número de linhas igual ao numero de reviews\"\n",
    "# assert len(features[0]) == seq_length, \"Cada linha deve ter o mesmo comprimento\"\n",
    "\n",
    "print(features_train[:3])\n",
    "print()\n",
    "print(features_test[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo o conjunto de treinamento em Treinamento, Validação e Teste\n",
    "\n",
    "> Vamos agora dividir o conjunto de treinamento em três  grupos: um de validação, o outro para treinamento e um final para teste (Escolhi fazer isso para ser mais uma estapa de mensuração do código antes de submetê-lo ao benchmarking -- que é o conjunto de testes lá de cima que viemos trabalhando até aqui). Para isso:\n",
    "* Vamos criar um conjunto das features para treino (`train_x`) e um conjunto de suas labels (`train_y`);\n",
    "* Definir uma fração de *split* (`split_frac`) para ser a fração dos dados a serem **mantidos** no conjunto de treinamento. (Geralmente é de 0.8 ou 0.9);\n",
    "* O Restante é dividido no meio, em conjunto de validação (`val_x` e `val_y`) e conjunto de teste (`test_x` e `test_y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\tShapes das features:\n",
      "Conjunto de treino: \t\t(124826, 52) \n",
      "Conjunto de Validação: \t\t(15603, 52) \n",
      "Conjunto de teste: \t\t(15604, 52)\n"
     ]
    }
   ],
   "source": [
    "# Escolhendo a fração de split:\n",
    "split_frac = 0.8\n",
    "\n",
    "# Índice do split\n",
    "split_idx = int(len(features_train)*split_frac)\n",
    "\n",
    "# Separando o conjunto de treino\n",
    "train_x, remaining_x = features_train[:split_idx], features_train[split_idx:]\n",
    "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
    "\n",
    "# Índice de split do restante\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    "\n",
    "print(\"\\t\\t\\t\\tShapes das features:\")\n",
    "print(\"Conjunto de treino: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nConjunto de Validação: \\t\\t{}\".format(val_x.shape),\n",
    "      \"\\nConjunto de teste: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando DataLoaders e Batching\n",
    "\n",
    "Agora estamos chegando na parte \"legal\" rsrs\n",
    "\n",
    "Agora que temos os nossos dados *bonitinhos* em mãos, precisamos de um método para criar nossos conjuntos de inputs de forma a minimizar o *overfitting* por conta de uma ordem específica presente nos dados.\n",
    "\n",
    "Uma forma é utilizando o [TensorDataset](https://pytorch.org/docs/stable/data.html#) para acessar os dados e criar os datasets. Utilizando a função *DataLoader* podemos criar pequenos *batchs*, escolhidos aleatoriamente dentre os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Criando os datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# Definindo o tamanho dos batchs\n",
    "batch_size = 128\n",
    "\n",
    "# Definindo os DataLoaders com o SHUFFLE ATIVADO (isso é importante!)\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do input da amostra:  torch.Size([128, 52])\n",
      "Input amostra: \n",
      " tensor([[    0,     0,     0,  ...,    16,   556,  4518],\n",
      "        [    0,     0,     0,  ...,     3,     1,    56],\n",
      "        [    0,     0,     0,  ...,   197,    10,   392],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,     0,     0, 11827],\n",
      "        [    0,     0,     0,  ...,     1,  5099,  3431],\n",
      "        [    0,     0,     0,  ...,     0,     0, 10288]])\n",
      "\n",
      "Tamanho do label da amostra:  torch.Size([128])\n",
      "Label amostra: \n",
      " tensor([0, 3, 2, 1, 1, 2, 2, 3, 2, 3, 1, 2, 3, 2, 2, 2, 1, 2, 2, 3, 1, 2, 1, 3,\n",
      "        3, 3, 2, 2, 2, 2, 3, 3, 4, 2, 2, 1, 1, 0, 0, 3, 3, 1, 2, 2, 2, 1, 1, 2,\n",
      "        3, 2, 2, 3, 1, 1, 1, 2, 2, 0, 2, 0, 2, 4, 2, 2, 0, 1, 3, 2, 1, 4, 1, 2,\n",
      "        2, 3, 1, 2, 2, 2, 1, 2, 3, 2, 3, 1, 3, 2, 3, 4, 0, 2, 4, 3, 3, 4, 3, 1,\n",
      "        2, 2, 2, 1, 2, 3, 0, 2, 1, 2, 2, 3, 2, 0, 2, 2, 4, 1, 2, 2, 2, 2, 2, 1,\n",
      "        1, 2, 2, 3, 2, 2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# Pegando um batch dos dados de treinamento:\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Tamanho do input da amostra: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Input amostra: \\n', sample_x)\n",
    "print()\n",
    "print('Tamanho do label da amostra: ', sample_y.size()) # batch_size\n",
    "print('Label amostra: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede de Sentimentos usando PyTorch\n",
    "\n",
    "Relembrando, vamos dividir a nossa rede em três principais componentes (camadas):\n",
    "1. Uma [camada de *embedding*](https://pytorch.org/docs/stable/nn.html#embedding) que converte os nossos tokens de palavras (inteiros) em vetores de um tamanho específico;\n",
    "2. Uma camada de [LSTM](https://pytorch.org/docs/stable/nn.html#lstm), que é definida pelo tamanho do `hidden_state` e pelo número de camadas;\n",
    "3. Uma camada de output totalmente conectada que mapeia os outputs da camada LSTM aos outputs do tamanho desejado (`output_size`);\n",
    "4. E por fim uma função ativadação *softmax* que transforma os outputs em probabilidades de classe.\n",
    "\n",
    "### A camada de *embedding*\n",
    "\n",
    "Precisamos de uma camada de embedding pois temos mais de 19000 palavras no nosso vocabuário (este inclusive pode ser um problema no geral, pois essa quantidade é relativamente baixa em comparação às +170000 palavras não-obsoletas existentes em inglês).\n",
    "\n",
    "### As camadas da LSTM\n",
    "\n",
    "A LSTM vai receber um tamanho de input `input_size`, a dimensão da camada oculta `hidden_dim`, o número de camadas, uma probabilidade de dropout (no caso de múltiplas camadas) e um parâmetro de `batch_first`.\n",
    "\n",
    "Na maioria das vezes, a rede pode ter entre 2 e 3 camadas. Adicionar essas camadas permite um aprendizado de relações mais complexas pela rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU nao disponivel, treinando na CPU.\n"
     ]
    }
   ],
   "source": [
    "# Podemos adicionar este código para verificar se a máquina possui GPU disponível para uso\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Trainando na GPU.')\n",
    "else:\n",
    "    print('GPU nao disponivel, treinando na CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Modelo de uma rede recorrente usada para realizar analise de sentimentos.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        # Aqui vamos inicializar a rede e os seus parâmetros \n",
    "        \n",
    "        super(SentimentRNN, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Camadas de embedding e da LSTM\n",
    "        # Na LSTM, deve-se colocar batch_first pois os tensores\n",
    "        # de input e output tem a forma: (batch, seq, feature)\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        \n",
    "        # Camada linear, dropout e softmax\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # Essa função é para realizar o forward pass do modelo no input e nos hidden states\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Embeddings e lstm_out\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "    \n",
    "        # Juntando os outputs da LSTM\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # Dropout e a camada totalmente conectada\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # Função LogSoftmax\n",
    "        soft_out = self.log_softmax(out)\n",
    "        \n",
    "        # Reshape para o batchfirst\n",
    "        soft_out = soft_out.view(batch_size, -1, self.output_size)\n",
    "        soft_out = soft_out[:, -1, :] # pega as labels(o output) da ultima posiçao te todas as linhas\n",
    "        \n",
    "        # Retorna o último output da softmax e do hidden state\n",
    "        return soft_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # Essa função inicializa o hidden state\n",
    "        \n",
    "        # Cria dois novos tensores de tamanho n_layers x batch_size x hidden_dim,\n",
    "        # inicializados com zeros, pra o hidden state e a cell state da LSTM\n",
    "        weight = next(self.parameters()).detach()\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciando a rede\n",
    "\n",
    "Vamos instanciar a rede definindo os parâmetros:\n",
    "* `vocab_size`: O tamanho do nosso vocabulário, ou o range dos valores do nosso input (tokens);\n",
    "* `output_size`: O tamanho do nosso output desejado; É o número de scores da nossa classe (0-4);\n",
    "* `embedding_dim`: Número de colunas na tabela do embedding; É o tamanho dos nossos embeddings;\n",
    "* `hidden_dim`: Número de unidades na camada oculta das nossas células de LSTM. Geralmente quanto maior, melhor a performance. Os tamanhos mais comuns são 128, 256, 512, etc.;\n",
    "* `n_layers`: É o número de camadas LSTM na rede. Geralmente ficam entre 1-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos então instanciar a rede com os hyperparâmetros:\n",
    "vocab_size = len(vocabulary_to_int) + 1 # +1 pelo padding de 0's\n",
    "output_size = 5\n",
    "embedding_dim = 200\n",
    "hidden_dim = 256\n",
    "n_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(19318, 200)\n",
      "  (lstm): LSTM(200, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=5, bias=True)\n",
      "  (log_softmax): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento\n",
    "\n",
    "Vamos estar usando a [CrossEntropyLoss](https://pytorch.org/docs/stable/nn.html#crossentropyloss), a chamada *Cross Entropy Loss*. Ela foi desenhada para trabalhar com problemas de classificação com C classes. \n",
    "\n",
    "Nesta fase também precisamos de outros *hyperparameters*:\n",
    "* `lr`: a learning rate do nosso otimizador escolhido;\n",
    "* `epochs`: o número de vezes que vamos iterar pelo dataset de treinamento;\n",
    "* `clip`: que é o valor máximo do gradiente para evitar o problema do \"explosive gradients\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "# Funções de otimização e de loss\n",
    "lr = 0.001\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.SGD(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/4... Step: 100... Loss: 0.733285... Val Loss: 1.068734\n",
      "Epoch: 1/4... Step: 200... Loss: 0.654291... Val Loss: 1.059251\n",
      "Epoch: 1/4... Step: 300... Loss: 0.669949... Val Loss: 1.083451\n",
      "Epoch: 1/4... Step: 400... Loss: 0.740750... Val Loss: 1.086438\n",
      "Epoch: 1/4... Step: 500... Loss: 0.725762... Val Loss: 1.047285\n",
      "Epoch: 1/4... Step: 600... Loss: 0.726553... Val Loss: 1.054882\n",
      "Epoch: 1/4... Step: 700... Loss: 0.837476... Val Loss: 1.057664\n",
      "Epoch: 1/4... Step: 800... Loss: 0.633633... Val Loss: 1.081536\n",
      "Epoch: 1/4... Step: 900... Loss: 0.651102... Val Loss: 1.058119\n",
      "Epoch: 2/4... Step: 1000... Loss: 0.560727... Val Loss: 1.102993\n",
      "Epoch: 2/4... Step: 1100... Loss: 0.693292... Val Loss: 1.089112\n",
      "Epoch: 2/4... Step: 1200... Loss: 0.666575... Val Loss: 1.116117\n",
      "Epoch: 2/4... Step: 1300... Loss: 0.745819... Val Loss: 1.103957\n",
      "Epoch: 2/4... Step: 1400... Loss: 0.702927... Val Loss: 1.062843\n",
      "Epoch: 2/4... Step: 1500... Loss: 0.744925... Val Loss: 1.060209\n",
      "Epoch: 2/4... Step: 1600... Loss: 0.769507... Val Loss: 1.059781\n",
      "Epoch: 2/4... Step: 1700... Loss: 0.864876... Val Loss: 1.042589\n",
      "Epoch: 2/4... Step: 1800... Loss: 0.578933... Val Loss: 1.057393\n",
      "Epoch: 2/4... Step: 1900... Loss: 0.629440... Val Loss: 1.069152\n",
      "Epoch: 3/4... Step: 2000... Loss: 0.651727... Val Loss: 1.125519\n",
      "Epoch: 3/4... Step: 2100... Loss: 0.683694... Val Loss: 1.148836\n",
      "Epoch: 3/4... Step: 2200... Loss: 0.756570... Val Loss: 1.120755\n",
      "Epoch: 3/4... Step: 2300... Loss: 0.650138... Val Loss: 1.097509\n",
      "Epoch: 3/4... Step: 2400... Loss: 0.602211... Val Loss: 1.096565\n",
      "Epoch: 3/4... Step: 2500... Loss: 0.703587... Val Loss: 1.101466\n",
      "Epoch: 3/4... Step: 2600... Loss: 0.803286... Val Loss: 1.094427\n",
      "Epoch: 3/4... Step: 2700... Loss: 0.552675... Val Loss: 1.092307\n",
      "Epoch: 3/4... Step: 2800... Loss: 0.609997... Val Loss: 1.083632\n",
      "Epoch: 3/4... Step: 2900... Loss: 0.922709... Val Loss: 1.087488\n",
      "Epoch: 4/4... Step: 3000... Loss: 0.635334... Val Loss: 1.169150\n",
      "Epoch: 4/4... Step: 3100... Loss: 0.483041... Val Loss: 1.122642\n",
      "Epoch: 4/4... Step: 3200... Loss: 0.694709... Val Loss: 1.111062\n",
      "Epoch: 4/4... Step: 3300... Loss: 0.864367... Val Loss: 1.120324\n",
      "Epoch: 4/4... Step: 3400... Loss: 0.520299... Val Loss: 1.108163\n",
      "Epoch: 4/4... Step: 3500... Loss: 0.725909... Val Loss: 1.093686\n",
      "Epoch: 4/4... Step: 3600... Loss: 0.706578... Val Loss: 1.106413\n",
      "Epoch: 4/4... Step: 3700... Loss: 0.653121... Val Loss: 1.102774\n",
      "Epoch: 4/4... Step: 3800... Loss: 0.583968... Val Loss: 1.092735\n",
      "Epoch: 4/4... Step: 3900... Loss: 0.690540... Val Loss: 1.104048\n"
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip = 5 # gradient clipping\n",
    "\n",
    "# Move o modelo para a GPU, se disponível\n",
    "# if(train_on_gpu):\n",
    "#     net.cuda()\n",
    "\n",
    "net.train()\n",
    "for e in range(epochs):\n",
    "    # Inicializando o hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "    \n",
    "    losses = []\n",
    "\n",
    "    # Loop pelo batch\n",
    "    for inputs, labels in train_loader:\n",
    "        if( (inputs.shape[0],inputs.shape[1]) != (batch_size,seq_length)):\n",
    "            print(\"Pulando problema no Shape do Input: \",inputs.shape)\n",
    "            continue\n",
    "        counter += 1\n",
    "        \n",
    "        #if(train_on_gpu):\n",
    "        #    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # Criando novo hidden state, para nao correr o risco de \n",
    "        # fazer o backprop por todo o historico de treinamento\n",
    "        h = tuple([each.detach() for each in h])\n",
    "\n",
    "        net.zero_grad()\n",
    "\n",
    "        output, h = net(inputs, h)\n",
    "        \n",
    "        loss = criterion(output.squeeze(), labels.long())\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # `clip_grad_norm` ajuda a prevenir o problema do \"exploding gradient\" nas RNNs e LSTMs\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        # Estatisticas da loss\n",
    "        if counter % print_every == 0:\n",
    "            \n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            \n",
    "            for inputs, labels in valid_loader:\n",
    "                \n",
    "                val_h = tuple([each.detach() for each in val_h])\n",
    "\n",
    "                #if(train_on_gpu):\n",
    "                #    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.long())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salvando o modelo:\n",
    "torch.save(net.state_dict(), 'sentiment_net.pt')\n",
    "\n",
    "# Para abrir:\n",
    "net.load_state_dict(torch.load('sentiment_net.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando a rede\n",
    "\n",
    "Existem algumas formas de testar uma rede neural. Podemos testá-la através de:\n",
    "\n",
    "* **Teste de performance dos dados**: Primeiro vemos como nosso modelo performa em todos os `test_data` lá de cima, calculando o loss médio e a acurácia sobre os dados de teste;\n",
    "* **Inferência em dados gerados pelo usuário**: Podemos inserir um review por vez (sem o label) e ver o que o modelo treinado retorna.\n",
    "\n",
    "Aqui vou me ater apenas ao primeiro caso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.127546\n",
      "\n",
      "Test Accuracy of     0: 17% (127/735)\n",
      "Test Accuracy of     1: 49% (1518/3094)\n",
      "Test Accuracy of     2: 70% (5311/7565)\n",
      "Test Accuracy of     3: 56% (1813/3197)\n",
      "Test Accuracy of     4: 19% (173/897)\n",
      "\n",
      "Test Accuracy (Overall): 57% (8942/15488)\n"
     ]
    }
   ],
   "source": [
    "# Pegando os dados de test_loss e de acurácia:\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(5))\n",
    "class_total = list(0. for i in range(5))\n",
    "\n",
    "h = net.init_hidden(batch_size)\n",
    "\n",
    "net.eval()\n",
    "for inputs, labels in test_loader:\n",
    "\n",
    "    h = tuple([each.data for each in h])\n",
    "\n",
    "#     if(train_on_gpu):\n",
    "#         inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "    output, h = net(inputs, h)\n",
    "\n",
    "    loss = criterion(output, labels.long())\n",
    "    \n",
    "    test_loss += loss.item()*inputs.size(0)\n",
    "    \n",
    "    # Convertendo as probabilidades do output para a classe prevista:\n",
    "    _, pred = torch.max(output, 1)\n",
    "    \n",
    "    # Comparando as previsões com o label verdadeiro:\n",
    "    correct = np.squeeze(pred.eq(labels.data.view_as(pred)))\n",
    "    \n",
    "    # Calculando a acurácia para cada classe de reviews\n",
    "    for i in range(len(labels)):\n",
    "        label = labels.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "\n",
    "### -- Status! -- ###\n",
    "# Calculando o test_loss medio\n",
    "test_loss = test_loss/len(test_loader.sampler)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(5):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            str(i), 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (100. * np.sum(class_correct) / np.sum(class_total), np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizei no total 8 treinos completos, sendo este último uma continuação do penúltimo (o que acabou acarretando em um overfitting).\n",
    "\n",
    "Os dados sobre os treinos eu deixei no arquivo texto 'treino-sentiment-rnn.txt' para consultas.\n",
    "\n",
    "Apenas nos dois últimos treinos que realizei a verificação, sendo a melhor acurácia total obtida a de 59% (treino anterior a esse último). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rápida conclusão\n",
    "\n",
    "Nesse desafio, vimos como realizar a implementação de uma rede neural recorrente capaz de prever sentimentos de reviews.\n",
    "\n",
    "Para uma boa implementação de um modelo como este, são necessárias três etapas importantes: A de organização e limpeza de dados, a escolha da arquitetura, e a fase de treinamento e validação. \n",
    "\n",
    "Por fim, é possivel aprimorarmos a rede se utilizarmos outros conjuntos de dados, por exemplo: com um conjunto de dados mais limpo (retirando as \"frases\" de comprimento menor que 3. É possível também buscarmos um vocabulário mais completo, e treinarmos uma camada de embedding separadamente da rede recorrente.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
